{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Entendimiento y Preparacion de los datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Carga de Datos y Librerias\n",
    "\n",
    "En este momento vamos a cargar los datos planos del archivo fake_news_spanish.csv para utilizarlo así como importar las librerias necesarias para el resto del notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[146], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, RegressorMixin\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import spacy\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import re, string, unicodedata\n",
    "import contractions\n",
    "import inflect\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "\n",
    "db_location = 'fake_news_spanish.csv'\n",
    "\n",
    "news_df=pd.read_csv(db_location, sep=';', encoding = \"UTF-8\") \n",
    "\n",
    "news_df = news_df.astype(str)\n",
    "\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2.1 Entendimiento de datos\n",
    "Para entender los datos procedemos a ver su estructura:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57063 entries, 0 to 57062\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ID           57063 non-null  object\n",
      " 1   Label        57063 non-null  object\n",
      " 2   Titulo       57063 non-null  object\n",
      " 3   Descripcion  57063 non-null  object\n",
      " 4   Fecha        57063 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "news_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver tenemos 5 columnas y 57 mil filas. De estas las mas importantes son las de \"Label\", \"Titulo\" y \"Descripcion\". Pues de estas vamos a obtener todas las variables para nuestro modelo de clasificación.\n",
    "\n",
    "### Estadísticas descriptivas\n",
    "\n",
    "Para entender las noticias vamos a realizar estadísticas descriptivas de los textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descripcion</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Conteo</th>\n",
       "      <th>Moda</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>'The Guardian' va con Sánchez: 'Europa necesit...</td>\n",
       "      <td>El diario británico publicó este pasado jueves...</td>\n",
       "      <td>02/06/2023</td>\n",
       "      <td>77</td>\n",
       "      <td>the</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>01/10/2023</td>\n",
       "      <td>104</td>\n",
       "      <td>el</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El 'Ahora o nunca' de Joan Fuster sobre el est...</td>\n",
       "      <td>El valencianismo convoca en Castelló su fiesta...</td>\n",
       "      <td>25/04/2022</td>\n",
       "      <td>77</td>\n",
       "      <td>el</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Iglesias alienta a Yolanda Díaz, ERC y EH Bild...</td>\n",
       "      <td>En política, igual que hay que negociar con lo...</td>\n",
       "      <td>03/01/2022</td>\n",
       "      <td>110</td>\n",
       "      <td>a</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>Puigdemont: 'No sería ninguna tragedia una rep...</td>\n",
       "      <td>En una entrevista en El Punt Avui, el líder de...</td>\n",
       "      <td>09/03/2018</td>\n",
       "      <td>72</td>\n",
       "      <td>puigdemont</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Label                                             Titulo  \\\n",
       "0  ID     1  'The Guardian' va con Sánchez: 'Europa necesit...   \n",
       "1  ID     0  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...   \n",
       "2  ID     1  El 'Ahora o nunca' de Joan Fuster sobre el est...   \n",
       "3  ID     1  Iglesias alienta a Yolanda Díaz, ERC y EH Bild...   \n",
       "4  ID     0  Puigdemont: 'No sería ninguna tragedia una rep...   \n",
       "\n",
       "                                         Descripcion       Fecha  Conteo  \\\n",
       "0  El diario británico publicó este pasado jueves...  02/06/2023      77   \n",
       "1  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...  01/10/2023     104   \n",
       "2  El valencianismo convoca en Castelló su fiesta...  25/04/2022      77   \n",
       "3  En política, igual que hay que negociar con lo...  03/01/2022     110   \n",
       "4  En una entrevista en El Punt Avui, el líder de...  09/03/2018      72   \n",
       "\n",
       "         Moda  Max  Min  \n",
       "0         the    9    2  \n",
       "1          el   10    1  \n",
       "2          el   10    1  \n",
       "3           a   12    1  \n",
       "4  puigdemont   11    2  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textos = news_df.copy()\n",
    "\n",
    "textos['Conteo'] = [len(str(x)) for x in textos['Titulo']]\n",
    "textos['Moda'] = [Counter([word.lower().strip(string.punctuation) for word in (str(i).split(' '))]).most_common()[0][0] for i in textos['Titulo']]\n",
    "textos['Max'] = [[max([len(x) for x in str(i).split(' ')])][0] for i in textos['Titulo']]\n",
    "textos['Min'] = [[min([len(x) for x in str(i).split(' ')])][0] for i in textos['Titulo']]\n",
    "\n",
    "textos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ydata_profiling import ProfileReport\n",
    "\n",
    "# # Assuming 'textos' is your DataFrame\n",
    "# profile = ProfileReport(textos, explorative=True)\n",
    "\n",
    "# # Display the report in the notebook\n",
    "# profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = news_df[[\"Label\", \"Titulo\", \"Descripcion\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Preparacion de datos\n",
    "\n",
    "Para preparar los datos vamos a seguir los pasos de procesamiento de texto tanto para el titúlo asi como las descripciones.\n",
    "\n",
    "### 2.2.1 Eliminación de Ruido\n",
    "\n",
    "Para eliminar el ruido vamos a eliminar cualquier instancia de caracter especial ($, @, ..., etc) y/o caracter de separacion (',', '.', ..., etc). Tambien vamos a estandarizar los caracteres para que todos se encuentren en minusculas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processWords(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    stop_words_set = set(stopwords.words('spanish'))\n",
    "    for word in words:\n",
    "        if word is not None:\n",
    "            new_word = word.lower()\n",
    "            if new_word not in stop_words_set:\n",
    "                new_word = unicodedata.normalize('NFKD', new_word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "                new_word = re.sub(r'[^\\w\\s]', '', new_word)\n",
    "                if new_word != '':\n",
    "                    new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def preprocessing(words):\n",
    "    words = processWords(words)\n",
    "    return words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Tokenización \n",
    "\n",
    "Se va a tokenizar cada palabra para que se pueda ingresar en una lista de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['TituloTok'] = news_df['Titulo'].apply(word_tokenize)\n",
    "news_df['DescripTok'] = news_df['Descripcion'].apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descripcion</th>\n",
       "      <th>TituloTok</th>\n",
       "      <th>DescripTok</th>\n",
       "      <th>TituloLimpio</th>\n",
       "      <th>DescripcionLimpio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>'The Guardian' va con Sánchez: 'Europa necesit...</td>\n",
       "      <td>El diario británico publicó este pasado jueves...</td>\n",
       "      <td>['The, Guardian, ', va, con, Sánchez, :, 'Euro...</td>\n",
       "      <td>[El, diario, británico, publicó, este, pasado,...</td>\n",
       "      <td>[the, guardian, va, sanchez, europa, necesita,...</td>\n",
       "      <td>[diario, britanico, publico, pasado, jueves, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>[REVELAN, QUE, EL, GOBIERNO, NEGOCIO, LA, LIBE...</td>\n",
       "      <td>[REVELAN, QUE, EL, GOBIERNO, NEGOCIO, LA, LIBE...</td>\n",
       "      <td>[revelan, gobierno, negocio, liberacion, mirel...</td>\n",
       "      <td>[revelan, gobierno, negocio, liberacion, mirel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>El 'Ahora o nunca' de Joan Fuster sobre el est...</td>\n",
       "      <td>El valencianismo convoca en Castelló su fiesta...</td>\n",
       "      <td>[El, 'Ahora, o, nunca, ', de, Joan, Fuster, so...</td>\n",
       "      <td>[El, valencianismo, convoca, en, Castelló, su,...</td>\n",
       "      <td>[ahora, nunca, joan, fuster, estatuto, valenci...</td>\n",
       "      <td>[valencianismo, convoca, castello, fiesta, gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Iglesias alienta a Yolanda Díaz, ERC y EH Bild...</td>\n",
       "      <td>En política, igual que hay que negociar con lo...</td>\n",
       "      <td>[Iglesias, alienta, a, Yolanda, Díaz, ,, ERC, ...</td>\n",
       "      <td>[En, política, ,, igual, que, hay, que, negoci...</td>\n",
       "      <td>[iglesias, alienta, yolanda, diaz, erc, eh, bi...</td>\n",
       "      <td>[politica, igual, negociar, empresarios, negoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Puigdemont: 'No sería ninguna tragedia una rep...</td>\n",
       "      <td>En una entrevista en El Punt Avui, el líder de...</td>\n",
       "      <td>[Puigdemont, :, 'No, sería, ninguna, tragedia,...</td>\n",
       "      <td>[En, una, entrevista, en, El, Punt, Avui, ,, e...</td>\n",
       "      <td>[puigdemont, no, ninguna, tragedia, repeticion...</td>\n",
       "      <td>[entrevista, punt, avui, lider, jxcat, desdram...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                             Titulo  \\\n",
       "0     1  'The Guardian' va con Sánchez: 'Europa necesit...   \n",
       "1     0  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...   \n",
       "2     1  El 'Ahora o nunca' de Joan Fuster sobre el est...   \n",
       "3     1  Iglesias alienta a Yolanda Díaz, ERC y EH Bild...   \n",
       "4     0  Puigdemont: 'No sería ninguna tragedia una rep...   \n",
       "\n",
       "                                         Descripcion  \\\n",
       "0  El diario británico publicó este pasado jueves...   \n",
       "1  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...   \n",
       "2  El valencianismo convoca en Castelló su fiesta...   \n",
       "3  En política, igual que hay que negociar con lo...   \n",
       "4  En una entrevista en El Punt Avui, el líder de...   \n",
       "\n",
       "                                           TituloTok  \\\n",
       "0  ['The, Guardian, ', va, con, Sánchez, :, 'Euro...   \n",
       "1  [REVELAN, QUE, EL, GOBIERNO, NEGOCIO, LA, LIBE...   \n",
       "2  [El, 'Ahora, o, nunca, ', de, Joan, Fuster, so...   \n",
       "3  [Iglesias, alienta, a, Yolanda, Díaz, ,, ERC, ...   \n",
       "4  [Puigdemont, :, 'No, sería, ninguna, tragedia,...   \n",
       "\n",
       "                                          DescripTok  \\\n",
       "0  [El, diario, británico, publicó, este, pasado,...   \n",
       "1  [REVELAN, QUE, EL, GOBIERNO, NEGOCIO, LA, LIBE...   \n",
       "2  [El, valencianismo, convoca, en, Castelló, su,...   \n",
       "3  [En, política, ,, igual, que, hay, que, negoci...   \n",
       "4  [En, una, entrevista, en, El, Punt, Avui, ,, e...   \n",
       "\n",
       "                                        TituloLimpio  \\\n",
       "0  [the, guardian, va, sanchez, europa, necesita,...   \n",
       "1  [revelan, gobierno, negocio, liberacion, mirel...   \n",
       "2  [ahora, nunca, joan, fuster, estatuto, valenci...   \n",
       "3  [iglesias, alienta, yolanda, diaz, erc, eh, bi...   \n",
       "4  [puigdemont, no, ninguna, tragedia, repeticion...   \n",
       "\n",
       "                                   DescripcionLimpio  \n",
       "0  [diario, britanico, publico, pasado, jueves, e...  \n",
       "1  [revelan, gobierno, negocio, liberacion, mirel...  \n",
       "2  [valencianismo, convoca, castello, fiesta, gra...  \n",
       "3  [politica, igual, negociar, empresarios, negoc...  \n",
       "4  [entrevista, punt, avui, lider, jxcat, desdram...  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['TituloLimpio']=news_df['TituloTok'].apply(preprocessing)\n",
    "news_df['DescripcionLimpio']=news_df['DescripTok'].apply(preprocessing)\n",
    "\n",
    "news_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>TituloLimpio</th>\n",
       "      <th>DescripcionLimpio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[the, guardian, va, sanchez, europa, necesita,...</td>\n",
       "      <td>[diario, britanico, publico, pasado, jueves, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[revelan, gobierno, negocio, liberacion, mirel...</td>\n",
       "      <td>[revelan, gobierno, negocio, liberacion, mirel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[ahora, nunca, joan, fuster, estatuto, valenci...</td>\n",
       "      <td>[valencianismo, convoca, castello, fiesta, gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[iglesias, alienta, yolanda, diaz, erc, eh, bi...</td>\n",
       "      <td>[politica, igual, negociar, empresarios, negoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[puigdemont, no, ninguna, tragedia, repeticion...</td>\n",
       "      <td>[entrevista, punt, avui, lider, jxcat, desdram...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                       TituloLimpio  \\\n",
       "0     1  [the, guardian, va, sanchez, europa, necesita,...   \n",
       "1     0  [revelan, gobierno, negocio, liberacion, mirel...   \n",
       "2     1  [ahora, nunca, joan, fuster, estatuto, valenci...   \n",
       "3     1  [iglesias, alienta, yolanda, diaz, erc, eh, bi...   \n",
       "4     0  [puigdemont, no, ninguna, tragedia, repeticion...   \n",
       "\n",
       "                                   DescripcionLimpio  \n",
       "0  [diario, britanico, publico, pasado, jueves, e...  \n",
       "1  [revelan, gobierno, negocio, liberacion, mirel...  \n",
       "2  [valencianismo, convoca, castello, fiesta, gra...  \n",
       "3  [politica, igual, negociar, empresarios, negoc...  \n",
       "4  [entrevista, punt, avui, lider, jxcat, desdram...  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = news_df[[\"Label\", \"TituloLimpio\", \"DescripcionLimpio\"]]\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Lematización\n",
    "\n",
    "Ahora vamos a lematizar las palabras, o de otra forma vamos a aplanar el lenguaje de las mismas (Corrió -> Correr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[145], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mes_core_news_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlemmaWords\u001b[39m(words):\n\u001b[0;32m      4\u001b[0m     new_words \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def lemmaWords(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_words.append(word.lemma_)\n",
    "    return new_words\n",
    "\n",
    "news_df['TituloLemm']=news_df['TituloLimpio'].apply(preprocessing)\n",
    "news_df['TituloLemm']=news_df['DescripcionLimpio'].apply(preprocessing)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
